{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SnBJE-sc_5r_",
        "outputId": "ee29c7d6-8528-404c-84bd-c5131462aa6f"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTEX9b-J_5sE"
      },
      "source": [
        "# Training data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyGjPQyASE16"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eJGvTZy8_5sH"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDJWWhCESKvF"
      },
      "source": [
        "## Check missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-ff9kZRSOSn",
        "outputId": "82a1639a-53e2-4e01-896c-a5839dc32345"
      },
      "outputs": [],
      "source": [
        "train_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI90AgDuSa1c"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_pipeline(df):\n",
        "    \n",
        "    # Split column \"Cabin\" into 3 columns: \"CabinDeck\", \"CabinNum\", \"CabinSide\"\n",
        "    df[['CabinDeck', 'CabinNum', 'CabinSide']] = df.Cabin.str.split('/', expand = True)\n",
        "\n",
        "    # Drop 3 columns \"PassengerId\", \"Name\" and \"Cabin\"\n",
        "    df = df.drop(['PassengerId', 'Name', 'Cabin'], axis='columns')\n",
        "\n",
        "    # Create a new feature \"TotalExpense\"\n",
        "    amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "    df['TotalExpense'] = df[amenities].sum(axis=1)\n",
        "\n",
        "    # Encode categorical data\n",
        "    cat_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'CabinDeck', 'CabinSide']\n",
        "    encoder = OrdinalEncoder().fit(df[cat_cols])\n",
        "    df[cat_cols] = encoder.transform(df[cat_cols])\n",
        "\n",
        "    if 'Transported' in df.columns:\n",
        "        df['Transported'] = list(map(int, df['Transported']))\n",
        "\n",
        "    # Impute missing values\n",
        "    miss_cols = df.isnull().sum()\n",
        "    miss_cols = list(miss_cols[miss_cols>0].index)\n",
        "    tf = ColumnTransformer([(\"imp\", SimpleImputer(strategy='mean'), miss_cols)])\n",
        "    df[miss_cols] = tf.fit_transform(df[miss_cols])\n",
        "\n",
        "    return df\n",
        "\n",
        "train_data = data_pipeline(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bg3gqqh_5sW"
      },
      "outputs": [],
      "source": [
        "X_train_data = train_data.drop('Transported', axis='columns')\n",
        "Y_train_data = train_data['Transported']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ0fqlMU_5sX"
      },
      "source": [
        "# Testing data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nImI8k0YTu2e"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHaY7Hpr_5sX"
      },
      "outputs": [],
      "source": [
        "X_test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# For writing to submission file\n",
        "PassengerIdTest = X_test_data['PassengerId']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFQNIp4AT3d2"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2T9-AUVfxnD"
      },
      "outputs": [],
      "source": [
        "X_test_data = data_pipeline(X_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK8OSrGK_5sb"
      },
      "source": [
        "# Training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmgQvAzYUuoQ"
      },
      "source": [
        "## CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsX30khGWZUG"
      },
      "outputs": [],
      "source": [
        "# Feature selection\n",
        "\n",
        "# model_fs = CatBoostClassifier(verbose=False)\n",
        "# sf = SequentialFeatureSelector(model_fs, scoring='accuracy', direction='backward', n_features_to_select='auto', tol=None)\n",
        "# sf.fit(X_train_data, Y_train_data)\n",
        "# best_features = list(sf.get_feature_names_out())\n",
        "\n",
        "# Avoid running the code again\n",
        "best_features = ['CryoSleep', 'RoomService', 'Spa', 'VRDeck', 'CabinDeck', 'CabinSide', 'TotalExpense']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ooIpxiVVOfwf"
      },
      "outputs": [],
      "source": [
        "# Model training and prediction\n",
        "\n",
        "clf = CatBoostClassifier(verbose=False)\n",
        "clf.fit(X_train_data[best_features], Y_train_data)\n",
        "prediction = clf.predict(X_test_data[best_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swPz279wMwZi",
        "outputId": "1e9a9da6-def2-468d-a220-cd7124f6d9fc"
      },
      "outputs": [],
      "source": [
        "# List parameters of the model\n",
        "\n",
        "clf.get_all_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao0H94A__5sf"
      },
      "outputs": [],
      "source": [
        "# Write to submission file\n",
        "\n",
        "res = pd.DataFrame(\n",
        "        {\n",
        "            'PassengerId': list(PassengerIdTest),\n",
        "            'Transported': [(p == 1) for p in list(prediction)]\n",
        "        }\n",
        "    )\n",
        "res.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unused code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## k-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym6uWLlC_5se"
      },
      "outputs": [],
      "source": [
        "# learning_rate_list = [0.05, 0.1, 0.5, 1, 2]\n",
        "# n_estimators_list = [100, 200, 500, 1000]\n",
        "# subsample_list = [0.5, 0.75, 1]\n",
        "\n",
        "# score_lists = []\n",
        "\n",
        "# kf = KFold(n_splits=5, shuffle=True)\n",
        "# folds_index = enumerate(kf.split(X_train_data))\n",
        "\n",
        "# # for each parameter\n",
        "# for l in learning_rate_list:\n",
        "#     score_lists.append([])\n",
        "#     for n in n_estimators_list:\n",
        "#         score_lists[-1].append([])\n",
        "#         for s in subsample_list:\n",
        "#             print(\"-\", l, n, s)\n",
        "#             fold_score = []\n",
        "\n",
        "#             # for each fold of a parameter\n",
        "#             for i, (train_index, validate_index) in folds_index:\n",
        "#                 X_fold_train_data = X_train_data.iloc[train_index]\n",
        "#                 Y_fold_train_data = Y_train_data.iloc[train_index]\n",
        "\n",
        "#                 X_fold_validate_data = X_train_data.iloc[validate_index]\n",
        "#                 Y_fold_validate_data = Y_train_data.iloc[validate_index]\n",
        "\n",
        "#                 clf = GradientBoostingClassifier(learning_rate=l, n_estimators=n, subsample=s)\n",
        "#                 clf.fit(X_fold_train_data, Y_fold_train_data)\n",
        "#                 fold_score.append(\n",
        "#                     clf.score(X_fold_validate_data, Y_fold_validate_data)\n",
        "#                 )\n",
        "                \n",
        "#             score_lists[-1][-1].append(np.mean(fold_score))\n",
        "\n",
        "# score_lists"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputation by logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # train_data[['PassengerGroup', 'HomePlanet']].groupby('PassengerGroup').nunique()\n",
        "# # sns.countplot(data=train_data, x='CabinDeck', hue='HomePlanet')\n",
        "\n",
        "# def impute_homeplanet(df):\n",
        "\n",
        "#     # LastName => HomePlanet\n",
        "#     LastName_HomePlanet_dict = df.loc[(df['LastName'].notnull() & df['HomePlanet'].notnull()), ['LastName', 'HomePlanet']].set_index('LastName').to_dict()['HomePlanet']\n",
        "#     df.loc[(df['LastName'].notnull() & df['HomePlanet'].isna()), 'HomePlanet'] = df.loc[(df['LastName'].notnull() & df['HomePlanet'].isna()), 'LastName'].map(LastName_HomePlanet_dict)\n",
        "\n",
        "#     # PassengerGroup => HomePlanet\n",
        "#     PassengerGroup_HomePlanet_dict = df.loc[df['HomePlanet'].notnull(), ['PassengerGroup', 'HomePlanet']].set_index('PassengerGroup').to_dict()['HomePlanet']\n",
        "#     df.loc[df['HomePlanet'].isna(), 'HomePlanet'] = df.loc[df['HomePlanet'].isna(), 'PassengerGroup'].map(PassengerGroup_HomePlanet_dict)\n",
        "\n",
        "#     # CabinDeck = A/B/C/T => HomePlanet = Europa\n",
        "#     df.loc[df['CabinDeck']=='A', 'HomePlanet'] = df.loc[df['CabinDeck']=='A', 'HomePlanet'].fillna('Europa')\n",
        "#     df.loc[df['CabinDeck']=='B', 'HomePlanet'] = df.loc[df['CabinDeck']=='B', 'HomePlanet'].fillna('Europa')\n",
        "#     df.loc[df['CabinDeck']=='C', 'HomePlanet'] = df.loc[df['CabinDeck']=='C', 'HomePlanet'].fillna('Europa')\n",
        "#     df.loc[df['CabinDeck']=='T', 'HomePlanet'] = df.loc[df['CabinDeck']=='T', 'HomePlanet'].fillna('Europa')\n",
        "\n",
        "#     # CabinDeck = G => HomePlanet = Earth\n",
        "#     df.loc[df['CabinDeck']=='G', 'HomePlanet'] = df.loc[df['CabinDeck']=='G', 'HomePlanet'].fillna('Earth')\n",
        "\n",
        "#     return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # train_data['SumAmenitiesZero'] = (train_data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1) == 0)\n",
        "# # sns.countplot(data=train_data, x='SumAmenitiesZero', hue='CryoSleep')\n",
        "\n",
        "# def impute_cryosleep(df):\n",
        "#     amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "\n",
        "#     # Sum of amenities > 0 => missing CryoSleep = False\n",
        "#     df.loc[df[amenities].sum(axis=1)>0, 'CryoSleep'] = df.loc[df[amenities].sum(axis=1)>0, 'CryoSleep'].fillna(False)\n",
        "\n",
        "#     # Sum of amenities = 0 => missing CryoSleep = True\n",
        "#     df.loc[df[amenities].sum(axis=1)==0, 'CryoSleep'] = df.loc[df[amenities].sum(axis=1)==0, 'CryoSleep'].fillna(True)\n",
        "    \n",
        "#     return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # train_data['RoomServiceZero'] = (train_data['RoomService'] == 0)\n",
        "# # sns.countplot(data=train_data, x='RoomServiceZero', hue='CryoSleep')\n",
        "\n",
        "# def impute_amenities(df):\n",
        "#     amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "    \n",
        "#     # CryoSleep = True => missing amenities = 0\n",
        "#     df.loc[df['CryoSleep']==True, amenities] = df.loc[df['CryoSleep']==True, amenities].fillna(0)\n",
        "\n",
        "#     # Sum of amenities = 0 => missing amenities = 0\n",
        "#     df.loc[df[amenities].sum(axis=1)==0, amenities] = df.loc[df[amenities].sum(axis=1)==0, amenities].fillna(0)\n",
        "\n",
        "#     # CryoSleep = False => missing amenities = mean of column\n",
        "#     for a in amenities:\n",
        "#         df.loc[df['CryoSleep']==False, a] = df.loc[df['CryoSleep']==False, a].fillna(df[a].mean())\n",
        "\n",
        "#     return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # train_data['Under18'] = (train_data['Age'] < 18)\n",
        "# # sns.countplot(data=train_data, x='Under18', hue='VIP')\n",
        "\n",
        "# # train_data['FromEarth'] = (train_data['HomePlanet'] == 'Earth')\n",
        "# # sns.countplot(data=train_data, x='FromEarth', hue='VIP')\n",
        "\n",
        "# # train_data['DeckG'] = (train_data['CabinDeck'] == 'G')\n",
        "# # sns.countplot(data=train_data, x='DeckG', hue='VIP')\n",
        "# # train_data['DeckT'] = (train_data['CabinDeck'] == 'T')\n",
        "# # sns.countplot(data=train_data, x='DeckT', hue='VIP')\n",
        "\n",
        "# def impute_vip(df):\n",
        "\n",
        "#     # Age < 18 => VIP = False\n",
        "#     df.loc[df['Age']<18, 'VIP'] = df.loc[df['Age']<18, 'VIP'].fillna(False)\n",
        "\n",
        "#     # HomePlanet = Earth => VIP = False\n",
        "#     df.loc[df['HomePlanet']=='Earth', 'VIP'] = df.loc[df['HomePlanet']=='Earth', 'VIP'].fillna(False)\n",
        "\n",
        "#     # CabinDeck = G or T => VIP False\n",
        "#     df.loc[df['CabinDeck']=='G', 'VIP'] = df.loc[df['CabinDeck']=='G', 'VIP'].fillna(False)\n",
        "#     df.loc[df['CabinDeck']=='T', 'VIP'] = df.loc[df['CabinDeck']=='T', 'VIP'].fillna(False)\n",
        "\n",
        "#     # (CabinDeck = not A to D) and (CryoSleep = False) => VIP True\n",
        "#     # df.loc[(df['CabinDeck'] not in ['A','B','C','D']) and (df['CryoSleep'] == False), 'VIP'] = df.loc[(df['CabinDeck'] not in ['A','B','C','D']) and (df['CryoSleep'] == False), 'VIP'].fillna(True)\n",
        "\n",
        "#     # CryoSleep = True => VIP = False (*** NOT SURE ***)\n",
        "#     # df.loc[df['CryoSleep']==True, 'VIP'] = df.loc[df['CryoSleep']==True, 'VIP'].fillna(False)\n",
        "\n",
        "#     # to be continued...\n",
        "\n",
        "#     return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def impute_age(df):\n",
        "#     amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "\n",
        "#     # Age by amenities expenses and CryoSleep\n",
        "#     df.loc[df[amenities].sum(axis=1)>0, 'Age'] = df.loc[df[amenities].sum(axis=1)>0, 'Age'].fillna(df.loc[df[amenities].sum(axis=1)>0, 'Age'].median())\n",
        "#     df.loc[(df[amenities].sum(axis=1)==0) & (df['CryoSleep']==False), 'Age'] = df.loc[(df[amenities].sum(axis=1)==0) & (df['CryoSleep']==False), 'Age'].fillna(df.loc[(df[amenities].sum(axis=1)==0) & (df['CryoSleep']==False), 'Age'].median())\n",
        "#     df.loc[(df[amenities].sum(axis=1)==0) & (df['CryoSleep']==True), 'Age'] = df.loc[(df[amenities].sum(axis=1)==0) & (df['CryoSleep']==True), 'Age'].fillna(df.loc[(df[amenities].sum(axis=1)==0) & (df['CryoSleep']==True), 'Age'].median())\n",
        "\n",
        "#     return df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1 (main, Dec 31 2022, 10:23:59) [GCC 12.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
