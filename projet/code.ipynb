{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from category_encoders import HashingEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "X_train_data = train_data.drop(['Transported'], axis='columns')\n",
    "Y_train_data = train_data['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(df):\n",
    "\n",
    "    ## Missing value\n",
    "    cat_col = ['HomePlanet','CryoSleep', 'Destination', 'VIP']\n",
    "    num_col = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "    # Using Simple Imputer to deal with missing value of categorical variables\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    imputer.fit(df[cat_col])\n",
    "    df[cat_col] = imputer.transform(df[cat_col])\n",
    "\n",
    "    # Using KNN Imputer to deal with missing value of numerical variables\n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    imputer.fit(df[num_col])\n",
    "    df[num_col] = imputer.transform(df[num_col])\n",
    "\n",
    "    # Remove missing value of cabin and name (because can not fill those missing value)\n",
    "    # df = df.dropna(axis='index')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = impute_data(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column(df):\n",
    "\n",
    "    # Create a column \"PassengerGroup\" from \"PassengerId\" \n",
    "    df['PassengerGroup'] = df['PassengerId'].str.split('_').str[0]\n",
    "\n",
    "    # Create column \"LastName\" from \"Name\"\n",
    "    df['LastName'] = df['Name'].str.split(' ').str[1]\n",
    "\n",
    "    # Split column \"Cabin\" into 3 columns \"CabinDeck\", \"CabinNum\", \"CabinSide\"\n",
    "    df[['CabinDeck', 'CabinNum', 'CabinSide']] = df.Cabin.str.split('/', expand = True)\n",
    "\n",
    "    # Drop 3 columns \"PassengerId\", \"Name\" and \"Cabin\"\n",
    "    df = df.drop(['PassengerId', 'Name', 'Cabin', 'CabinNum'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = split_column(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean to integer: 0 = False, 1 = True\n",
    "\n",
    "def bool_to_int(df):\n",
    "    df['CryoSleep'] = list(map(int, df['CryoSleep']))\n",
    "    df['VIP'] = list(map(int, df['VIP']))\n",
    "    return df\n",
    "\n",
    "X_train_data = bool_to_int(X_train_data)\n",
    "\n",
    "Y_train_data = pd.Series(list(map(int, Y_train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_variable(df):\n",
    "\n",
    "    # Create dummy variables and drop original ones\n",
    "\n",
    "    HomePlanetDummies = pd.get_dummies(df['HomePlanet'], prefix='HomePlanet')\n",
    "    df = pd.concat([df, HomePlanetDummies], axis='columns')\n",
    "\n",
    "    DestinationDummies = pd.get_dummies(df['Destination'], prefix='Destination')\n",
    "    df = pd.concat([df, DestinationDummies], axis='columns')\n",
    "\n",
    "    CabinDeckDummies = pd.get_dummies(df['CabinDeck'], prefix='CabinDeck')\n",
    "    df = pd.concat([df, CabinDeckDummies], axis='columns')\n",
    "\n",
    "    CabinSideDummies = pd.get_dummies(df['CabinSide'], prefix='CabinSide')\n",
    "    df = pd.concat([df, CabinSideDummies], axis='columns')\n",
    "\n",
    "    df = df.drop(['HomePlanet', 'Destination', 'CabinDeck', 'CabinSide'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = dummy_variable(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashing_encode(df):\n",
    "\n",
    "    # Using feature hashing to encode PassengerGroup, CabinDeck and LastName\n",
    "\n",
    "    encoder = HashingEncoder(cols='PassengerGroup',n_components=5)\n",
    "    PassengerGroupDummies = pd.DataFrame(encoder.fit_transform(df['PassengerGroup']))\n",
    "    PassengerGroupDummies = PassengerGroupDummies.add_prefix('PassengerGroup_')\n",
    "    df = pd.concat([df, PassengerGroupDummies], axis='columns')\n",
    "\n",
    "    # encoder = HashingEncoder(cols='CabinDeck',n_components=5)\n",
    "    # CabinDeckDummies = pd.DataFrame(encoder.fit_transform(df['CabinDeck']))\n",
    "    # CabinDeckDummies = CabinDeckDummies.add_prefix('CabinDeck_')\n",
    "    # df = pd.concat([df, CabinDeckDummies], axis='columns')\n",
    "\n",
    "    encoder = HashingEncoder(cols='LastName',n_components=5)\n",
    "    LastNameDummies = pd.DataFrame(encoder.fit_transform(df['LastName']))\n",
    "    LastNameDummies = LastNameDummies.add_prefix('LastName_')\n",
    "    df = pd.concat([df, LastNameDummies], axis='columns')\n",
    "\n",
    "    # df = df.drop(['PassengerGroup', 'CabinDeck', 'LastName'], axis='columns')\n",
    "    df = df.drop(['PassengerGroup', 'LastName'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = hashing_encode(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_data)\n",
    "\n",
    "X_train_data = pd.DataFrame(scaler.transform(X_train_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "X_test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# For writing to submission file\n",
    "PassengerIdTest = X_test_data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = impute_data(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = split_column(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = bool_to_int(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = dummy_variable(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = hashing_encode(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "X_test_data = pd.DataFrame(scaler.transform(X_test_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegression().fit(X_train_data, Y_train_data)\n",
    "# prediction = clf.predict(X_test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross validation, testing different values of C parameter\n",
    "\n",
    "# C_list = [0.01, 0.1, 0.5, 1, 1.5, 2, 3, 5]\n",
    "# C_score = []\n",
    "\n",
    "# for c in C_list:\n",
    "#     print(\"C =\", c)\n",
    "#     clf = LinearSVC(C=c)\n",
    "#     cv_res = cross_validate(clf, X_train_data, Y_train_data, cv=5)\n",
    "#     C_score.append(cv_res['test_score'].mean())\n",
    "\n",
    "# C_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K fold cross validation\n",
    "\n",
    "C_list = [0.01, 0.1, 0.5, 1, 1.5, 2, 3, 5]\n",
    "C_score = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# for each parameter\n",
    "for c in C_list:\n",
    "    fold_score = []\n",
    "\n",
    "    # for each fold of a parameter\n",
    "    for i, (train_index, validate_index) in enumerate(kf.split(X_train_data)):\n",
    "        X_fold_train_data = X_train_data.iloc[train_index]\n",
    "        Y_fold_train_data = Y_train_data.iloc[train_index]\n",
    "\n",
    "        X_fold_validate_data = X_train_data.iloc[validate_index]\n",
    "        Y_fold_validate_data = Y_train_data.iloc[validate_index]\n",
    "\n",
    "        clf = LinearSVC(C=c)\n",
    "        clf.fit(X_fold_train_data, Y_fold_train_data)\n",
    "        fold_score.append(\n",
    "            clf.score(X_fold_validate_data, Y_fold_validate_data)\n",
    "        )\n",
    "    \n",
    "    C_score.append(np.mean(fold_score))\n",
    "\n",
    "C_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train with best value of C and predict\n",
    "\n",
    "# clf = LinearSVC().fit(X_train_data, Y_train_data)\n",
    "# prediction = clf.predict(X_test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.DataFrame(\n",
    "#         {\n",
    "#             'PassengerId': list(PassengerIdTest),\n",
    "#             'Transported': [(p == 1) for p in list(prediction)]\n",
    "#         }\n",
    "#     )\n",
    "# res.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
