{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from category_encoders import HashingEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB   \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "X_train_data = train_data.drop(['Transported'], axis='columns')\n",
    "Y_train_data = train_data['Transported']\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(df):\n",
    "\n",
    "    ## Missing value\n",
    "    cat_col = ['HomePlanet','CryoSleep', 'Destination', 'VIP']\n",
    "    num_col = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "    # Using Simple Imputer to deal with missing value of categorical variables\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    imputer.fit(df[cat_col])\n",
    "    df[cat_col] = imputer.transform(df[cat_col])\n",
    "\n",
    "    # Using KNN Imputer to deal with missing value of numerical variables\n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    imputer.fit(df[num_col])\n",
    "    df[num_col] = imputer.transform(df[num_col])\n",
    "\n",
    "    # Remove missing value of cabin and name (because can not fill those missing value)\n",
    "    # df = df.dropna(axis='index')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = impute_data(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column(df):\n",
    "\n",
    "    # Create a column \"PassengerGroup\" from \"PassengerId\" \n",
    "    df['PassengerGroup'] = df['PassengerId'].str.split('_').str[0]\n",
    "\n",
    "    # Create column \"LastName\" from \"Name\"\n",
    "    df['LastName'] = df['Name'].str.split(' ').str[1]\n",
    "\n",
    "    # Split column \"Cabin\" into 3 columns \"CabinDeck\", \"CabinNum\", \"CabinSide\"\n",
    "    df[['CabinDeck', 'CabinNum', 'CabinSide']] = df.Cabin.str.split('/', expand = True)\n",
    "\n",
    "    # Drop 3 columns \"PassengerId\", \"Name\" and \"Cabin\"\n",
    "    df = df.drop(['PassengerId', 'Name', 'Cabin', 'CabinNum'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = split_column(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean to integer: 0 = False, 1 = True\n",
    "\n",
    "def bool_to_int(df):\n",
    "    df['CryoSleep'] = list(map(int, df['CryoSleep']))\n",
    "    df['VIP'] = list(map(int, df['VIP']))\n",
    "    return df\n",
    "\n",
    "X_train_data = bool_to_int(X_train_data)\n",
    "\n",
    "Y_train_data = pd.Series(list(map(int, Y_train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_variable(df):\n",
    "\n",
    "    # Create dummy variables and drop original ones\n",
    "\n",
    "    HomePlanetDummies = pd.get_dummies(df['HomePlanet'], prefix='HomePlanet')\n",
    "    df = pd.concat([df, HomePlanetDummies], axis='columns')\n",
    "\n",
    "    DestinationDummies = pd.get_dummies(df['Destination'], prefix='Destination')\n",
    "    df = pd.concat([df, DestinationDummies], axis='columns')\n",
    "\n",
    "    CabinDeckDummies = pd.get_dummies(df['CabinDeck'], prefix='CabinDeck')\n",
    "    df = pd.concat([df, CabinDeckDummies], axis='columns')\n",
    "\n",
    "    CabinSideDummies = pd.get_dummies(df['CabinSide'], prefix='CabinSide')\n",
    "    df = pd.concat([df, CabinSideDummies], axis='columns')\n",
    "\n",
    "    df = df.drop(['HomePlanet', 'Destination', 'CabinDeck', 'CabinSide'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = dummy_variable(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashing_encode(df):\n",
    "\n",
    "    # Using feature hashing to encode PassengerGroup, CabinDeck and LastName\n",
    "\n",
    "    encoder = HashingEncoder(cols='PassengerGroup',n_components=5)\n",
    "    PassengerGroupDummies = pd.DataFrame(encoder.fit_transform(df['PassengerGroup']))\n",
    "    PassengerGroupDummies = PassengerGroupDummies.add_prefix('PassengerGroup_')\n",
    "    df = pd.concat([df, PassengerGroupDummies], axis='columns')\n",
    "\n",
    "    # encoder = HashingEncoder(cols='CabinDeck',n_components=5)\n",
    "    # CabinDeckDummies = pd.DataFrame(encoder.fit_transform(df['CabinDeck']))\n",
    "    # CabinDeckDummies = CabinDeckDummies.add_prefix('CabinDeck_')\n",
    "    # df = pd.concat([df, CabinDeckDummies], axis='columns')\n",
    "\n",
    "    encoder = HashingEncoder(cols='LastName',n_components=5)\n",
    "    LastNameDummies = pd.DataFrame(encoder.fit_transform(df['LastName']))\n",
    "    LastNameDummies = LastNameDummies.add_prefix('LastName_')\n",
    "    df = pd.concat([df, LastNameDummies], axis='columns')\n",
    "\n",
    "    # df = df.drop(['PassengerGroup', 'CabinDeck', 'LastName'], axis='columns')\n",
    "    df = df.drop(['PassengerGroup', 'LastName'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = hashing_encode(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_data)\n",
    "\n",
    "X_train_data = pd.DataFrame(scaler.transform(X_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "X_test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# For writing to submission file\n",
    "PassengerIdTest = X_test_data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = impute_data(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = split_column(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = bool_to_int(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = dummy_variable(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = hashing_encode(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "X_test_data = pd.DataFrame(scaler.transform(X_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegression().fit(X_train_data, Y_train_data)\n",
    "# prediction = clf.predict(X_test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross validation, testing different values of C parameter\n",
    "\n",
    "# C_list = [0.01, 0.1, 0.5, 1, 1.5, 2, 3, 5]\n",
    "# C_score = []\n",
    "\n",
    "# for c in C_list:\n",
    "#     print(\"C =\", c)\n",
    "#     clf = LinearSVC(C=c)\n",
    "#     cv_res = cross_validate(clf, X_train_data, Y_train_data, cv=5)\n",
    "#     C_score.append(cv_res['test_score'].mean())\n",
    "\n",
    "# C_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K fold cross validation\n",
    "\n",
    "# C_list = [2,2.5,3,3.5]\n",
    "# C_score = []\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# # for each parameter\n",
    "# for c in C_list:\n",
    "#     print(\"-\", c)\n",
    "#     fold_score = []\n",
    "\n",
    "#     # for each fold of a parameter\n",
    "#     for i, (train_index, validate_index) in enumerate(kf.split(X_train_data)):\n",
    "#         X_fold_train_data = X_train_data.iloc[train_index]\n",
    "#         Y_fold_train_data = Y_train_data.iloc[train_index]\n",
    "\n",
    "#         X_fold_validate_data = X_train_data.iloc[validate_index]\n",
    "#         Y_fold_validate_data = Y_train_data.iloc[validate_index]\n",
    "\n",
    "#         clf = SVC(C=c)\n",
    "#         clf.fit(X_fold_train_data, Y_fold_train_data)\n",
    "#         fold_score.append(\n",
    "#             clf.score(X_fold_validate_data, Y_fold_validate_data)\n",
    "#         )\n",
    "    \n",
    "#     C_score.append(np.mean(fold_score))\n",
    "\n",
    "# C_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "- SVC(C=2.5): 0.79471\n",
    "- LogisticRegression(): 0.79214\n",
    "- GaussianNB(): 0.72901\n",
    "- DecisionTreeClassifier(): 0.72854\n",
    "- LinearSVC(): 0.71475"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with best value of C and predict\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train_data, Y_train_data)\n",
    "prediction = clf.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(\n",
    "        {\n",
    "            'PassengerId': list(PassengerIdTest),\n",
    "            'Transported': [(p == 1) for p in list(prediction)]\n",
    "        }\n",
    "    )\n",
    "res.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
