{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babe1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from category_encoders import HashingEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c188b",
   "metadata": {},
   "source": [
    "# Training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6576616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "X_train_data = train_data.drop(['Transported'], axis='columns')\n",
    "Y_train_data = train_data['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2607cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(df):\n",
    "\n",
    "    ## Missing value\n",
    "    cat_col = ['HomePlanet','CryoSleep', 'Destination', 'VIP']\n",
    "    num_col = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "    # Using Simple Imputer to deal with missing value of categorical variables\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    imputer.fit(df[cat_col])\n",
    "    df[cat_col] = imputer.transform(df[cat_col])\n",
    "\n",
    "    # Using KNN Imputer to deal with missing value of numerical variables\n",
    "    imputer = KNNImputer(n_neighbors=int(np.sqrt(len(df.index))))\n",
    "    imputer.fit(df[num_col])\n",
    "    df[num_col] = imputer.transform(df[num_col])\n",
    "\n",
    "    # Remove missing value of cabin and name (because can not fill those missing value)\n",
    "    # df = df.dropna(axis='index')\n",
    "\n",
    "    return df\n",
    "\n",
    "def impute_data2(df):\n",
    "        \n",
    "    # For passengers in CryoSleep we impute zero for missing amenities values\n",
    "    amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    df.loc[df.CryoSleep.eq(True), amenities] = 0\n",
    "    \n",
    "    ## Missing value\n",
    "    cat_col = ['HomePlanet','CryoSleep', 'Destination', 'VIP']\n",
    "    num_col = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "    # Using Simple Imputer to deal with missing value of categorical variables\n",
    "    imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    imputer.fit(df[cat_col])\n",
    "    df[cat_col] = imputer.transform(df[cat_col])\n",
    "\n",
    "    # Using KNN Imputer to deal with missing value of numerical variables\n",
    "    imputer = KNNImputer(n_neighbors=int(np.sqrt(len(df.index))))\n",
    "    imputer.fit(df[num_col])\n",
    "    df[num_col] = imputer.transform(df[num_col])\n",
    "\n",
    "    # Remove missing value of cabin and name (because can not fill those missing value)\n",
    "    # df = df.dropna(axis='index')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = impute_data2(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863a3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column(df):\n",
    "\n",
    "    # Create a column \"PassengerGroup\" from \"PassengerId\" \n",
    "    df['PassengerGroup'] = df['PassengerId'].str.split('_').str[0]\n",
    "\n",
    "    # Create column \"LastName\" from \"Name\"\n",
    "    df['LastName'] = df['Name'].str.split(' ').str[1]\n",
    "\n",
    "    # Split column \"Cabin\" into 3 columns \"CabinDeck\", \"CabinNum\", \"CabinSide\"\n",
    "    df[['CabinDeck', 'CabinNum', 'CabinSide']] = df.Cabin.str.split('/', expand = True)\n",
    "\n",
    "    # Drop 3 columns \"PassengerId\", \"Name\" and \"Cabin\"\n",
    "    df = df.drop(['PassengerId', 'Name', 'Cabin', 'CabinNum'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = split_column(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9da51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean to integer: 0 = False, 1 = True\n",
    "\n",
    "def bool_to_int(df):\n",
    "    df['CryoSleep'] = list(map(int, df['CryoSleep']))\n",
    "    df['VIP'] = list(map(int, df['VIP']))\n",
    "    return df\n",
    "\n",
    "X_train_data = bool_to_int(X_train_data)\n",
    "\n",
    "Y_train_data = pd.Series(list(map(int, Y_train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea01caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_variable(df):\n",
    "\n",
    "    # Create dummy variables and drop original ones\n",
    "\n",
    "    HomePlanetDummies = pd.get_dummies(df['HomePlanet'], prefix='HomePlanet')\n",
    "    df = pd.concat([df, HomePlanetDummies], axis='columns')\n",
    "\n",
    "    DestinationDummies = pd.get_dummies(df['Destination'], prefix='Destination')\n",
    "    df = pd.concat([df, DestinationDummies], axis='columns')\n",
    "\n",
    "    CabinDeckDummies = pd.get_dummies(df['CabinDeck'], prefix='CabinDeck')\n",
    "    df = pd.concat([df, CabinDeckDummies], axis='columns')\n",
    "\n",
    "    CabinSideDummies = pd.get_dummies(df['CabinSide'], prefix='CabinSide')\n",
    "    df = pd.concat([df, CabinSideDummies], axis='columns')\n",
    "\n",
    "    df = df.drop(['HomePlanet', 'Destination', 'CabinDeck', 'CabinSide'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = dummy_variable(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3968caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashing_encode(df):\n",
    "\n",
    "    # Using feature hashing to encode PassengerGroup, CabinDeck and LastName\n",
    "\n",
    "    encoder = HashingEncoder(cols='PassengerGroup',n_components=10)\n",
    "    PassengerGroupDummies = pd.DataFrame(encoder.fit_transform(df['PassengerGroup']))\n",
    "    PassengerGroupDummies = PassengerGroupDummies.add_prefix('PassengerGroup_')\n",
    "    df = pd.concat([df, PassengerGroupDummies], axis='columns')\n",
    "\n",
    "    # encoder = HashingEncoder(cols='CabinDeck',n_components=5)\n",
    "    # CabinDeckDummies = pd.DataFrame(encoder.fit_transform(df['CabinDeck']))\n",
    "    # CabinDeckDummies = CabinDeckDummies.add_prefix('CabinDeck_')\n",
    "    # df = pd.concat([df, CabinDeckDummies], axis='columns')\n",
    "\n",
    "    encoder = HashingEncoder(cols='LastName',n_components=5)\n",
    "    LastNameDummies = pd.DataFrame(encoder.fit_transform(df['LastName']))\n",
    "    LastNameDummies = LastNameDummies.add_prefix('LastName_')\n",
    "    df = pd.concat([df, LastNameDummies], axis='columns')\n",
    "\n",
    "    # df = df.drop(['PassengerGroup', 'CabinDeck', 'LastName'], axis='columns')\n",
    "    df = df.drop(['PassengerGroup', 'LastName'], axis='columns')\n",
    "\n",
    "    return df\n",
    "\n",
    "X_train_data = hashing_encode(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33c56714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler = StandardScaler().fit(X_train_data)\\n\\nX_train_data = pd.DataFrame(scaler.transform(X_train_data))\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardization\n",
    "\"\"\"\n",
    "scaler = StandardScaler().fit(X_train_data)\n",
    "\n",
    "X_train_data = pd.DataFrame(scaler.transform(X_train_data))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385e95a",
   "metadata": {},
   "source": [
    "# Testing data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "153ce523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "X_test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# For writing to submission file\n",
    "PassengerIdTest = X_test_data['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20784ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = impute_data2(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "789a4181",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = split_column(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a10f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = bool_to_int(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8923de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = dummy_variable(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a96e7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = hashing_encode(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5f0837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_test_data = pd.DataFrame(scaler.transform(X_test_data))\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardization\n",
    "\n",
    "\"\"\"\n",
    "X_test_data = pd.DataFrame(scaler.transform(X_test_data))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d9ecb",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e4387",
   "metadata": {},
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59fdc5a",
   "metadata": {},
   "source": [
    "##### AGE experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2491a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data[\"Age\"] = pd.cut(x=X_train_data[\"Age\"].astype(float), bins=[0,10,20,60,float('inf')], labels=['chilf','teenager','adult','old'])\n",
    "encoder = HashingEncoder(cols='Age',n_components=4)\n",
    "AgeDummies = pd.DataFrame(encoder.fit_transform(X_train_data['Age']))\n",
    "AgeDummies = AgeDummies.add_prefix('Age_')\n",
    "X_train_data = pd.concat([X_train_data, AgeDummies], axis='columns')\n",
    "\n",
    "X_test_data[\"Age\"] = pd.cut(x=X_test_data[\"Age\"].astype(float), bins=[0,10,20,60,float('inf')], labels=['chilf','teenager','adult','old'])\n",
    "encoder = HashingEncoder(cols='Age',n_components=4)\n",
    "AgeDummies = pd.DataFrame(encoder.fit_transform(X_test_data['Age']))\n",
    "AgeDummies = AgeDummies.add_prefix('Age_')\n",
    "X_test_data = pd.concat([X_test_data, AgeDummies], axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59498668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = X_train_data.drop(['Age'], axis='columns')\n",
    "X_test_data = X_test_data.drop(['Age'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1ff63ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.005, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.005, n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.005, n_estimators=500)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = lgb.LGBMClassifier(boosting_type ='gbdt', learning_rate = 0.005, n_estimators = 500, num_leaves = 31)\n",
    "lgbm.fit(X_train_data, Y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee461ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lgbm.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc86ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(\n",
    "{\n",
    "             'PassengerId': list(PassengerIdTest),\n",
    "             'Transported': [(p == 1) for p in list(prediction)]\n",
    "         }\n",
    ")\n",
    "res.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8d378",
   "metadata": {},
   "source": [
    "### Variable Selection using RFE (BEST ATTEMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "150abbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def select_features_with_rfe(X, y, n_splits=5):\n",
    "    \"\"\"\n",
    "    Performs feature selection on a pandas DataFrame using Recursive Feature Elimination with cross-validation.\n",
    "\n",
    "    Args:\n",
    "        X (pandas.DataFrame): DataFrame containing the features.\n",
    "        y (pandas.Series): Series containing the target variable.\n",
    "        n_splits (int): Number of folds to use for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: New DataFrame containing the selected features and target variable.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up a LightGBM model\n",
    "    model = LGBMClassifier(objective='binary', metric='accuracy', feature_fraction=0.8, lambda_l1=0.1, lambda_l2=0.1)\n",
    "\n",
    "    # Set up recursive feature elimination with cross-validation\n",
    "    rfecv = RFECV(estimator=model, step=1, cv=KFold(n_splits=n_splits, shuffle=True, random_state=42), scoring='accuracy')\n",
    "\n",
    "    # Fit the recursive feature elimination to the data\n",
    "    rfecv.fit(X, y)\n",
    "\n",
    "    # Get the selected features\n",
    "    selected_features = X.columns[rfecv.support_]\n",
    "\n",
    "    # Create a new DataFrame with the selected features and target variable\n",
    "    selected_df = X[selected_features]\n",
    "    #selected_df['target'] = y\n",
    "\n",
    "    return selected_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8729e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=select_features_with_rfe(X_train_data, Y_train_data, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d11c1581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CryoSleep', 'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa',\n",
       "       'VRDeck', 'HomePlanet_Earth', 'HomePlanet_Europa', 'HomePlanet_Mars',\n",
       "       'Destination_55 Cancri e', 'Destination_PSO J318.5-22',\n",
       "       'Destination_TRAPPIST-1e', 'CabinDeck_A', 'CabinDeck_B', 'CabinDeck_C',\n",
       "       'CabinDeck_D', 'CabinDeck_E', 'CabinDeck_F', 'CabinDeck_G',\n",
       "       'CabinSide_P', 'CabinSide_S', 'PassengerGroup_col_0',\n",
       "       'PassengerGroup_col_1', 'PassengerGroup_col_2', 'PassengerGroup_col_3',\n",
       "       'PassengerGroup_col_4', 'PassengerGroup_col_5', 'PassengerGroup_col_6',\n",
       "       'PassengerGroup_col_8', 'PassengerGroup_col_9', 'LastName_col_0',\n",
       "       'LastName_col_1', 'LastName_col_3', 'LastName_col_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "63aa69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_variable_selection = X_test_data[['CryoSleep', 'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa',\n",
    "       'VRDeck', 'HomePlanet_Earth', 'HomePlanet_Europa', 'HomePlanet_Mars',\n",
    "       'Destination_55 Cancri e', 'Destination_PSO J318.5-22',\n",
    "       'Destination_TRAPPIST-1e', 'CabinDeck_A', 'CabinDeck_B', 'CabinDeck_C',\n",
    "       'CabinDeck_D', 'CabinDeck_E', 'CabinDeck_F', 'CabinDeck_G',\n",
    "       'CabinSide_P', 'CabinSide_S', 'PassengerGroup_col_0',\n",
    "       'PassengerGroup_col_1', 'PassengerGroup_col_2', 'PassengerGroup_col_3',\n",
    "       'PassengerGroup_col_4', 'PassengerGroup_col_5', 'PassengerGroup_col_6',\n",
    "       'PassengerGroup_col_8', 'PassengerGroup_col_9', 'LastName_col_0',\n",
    "       'LastName_col_1', 'LastName_col_3', 'LastName_col_4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "76ac88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction using selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9188f0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.005, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.005, n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.005, n_estimators=500)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = lgb.LGBMClassifier(boosting_type ='gbdt', learning_rate = 0.005, n_estimators = 500, num_leaves = 31)\n",
    "lgbm.fit(df, Y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a3cb3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lgbm.predict(X_test_variable_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f423c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(\n",
    "{\n",
    "             'PassengerId': list(PassengerIdTest),\n",
    "             'Transported': [(p == 1) for p in list(prediction)]\n",
    "         }\n",
    ")\n",
    "res.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "87d17979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>...</th>\n",
       "      <th>PassengerGroup_col_5</th>\n",
       "      <th>PassengerGroup_col_6</th>\n",
       "      <th>PassengerGroup_col_7</th>\n",
       "      <th>PassengerGroup_col_8</th>\n",
       "      <th>PassengerGroup_col_9</th>\n",
       "      <th>LastName_col_0</th>\n",
       "      <th>LastName_col_1</th>\n",
       "      <th>LastName_col_2</th>\n",
       "      <th>LastName_col_3</th>\n",
       "      <th>LastName_col_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>1</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>1</td>\n",
       "      <td>26.646154</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>0</td>\n",
       "      <td>35.169231</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>1</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CryoSleep        Age  VIP  RoomService  FoodCourt  ShoppingMall     Spa  \\\n",
       "0             1  27.000000    0          0.0        0.0           0.0     0.0   \n",
       "1             0  19.000000    0          0.0        9.0           0.0  2823.0   \n",
       "2             1  31.000000    0          0.0        0.0           0.0     0.0   \n",
       "3             0  38.000000    0          0.0     6652.0           0.0   181.0   \n",
       "4             0  20.000000    0         10.0        0.0         635.0     0.0   \n",
       "...         ...        ...  ...          ...        ...           ...     ...   \n",
       "4272          1  34.000000    0          0.0        0.0           0.0     0.0   \n",
       "4273          0  42.000000    0          0.0      847.0          17.0    10.0   \n",
       "4274          1  26.646154    0          0.0        0.0           0.0     0.0   \n",
       "4275          0  35.169231    0          0.0     2680.0           0.0     0.0   \n",
       "4276          1  43.000000    0          0.0        0.0           0.0     0.0   \n",
       "\n",
       "      VRDeck  HomePlanet_Earth  HomePlanet_Europa  ...  PassengerGroup_col_5  \\\n",
       "0        0.0                 1                  0  ...                     0   \n",
       "1        0.0                 1                  0  ...                     0   \n",
       "2        0.0                 0                  1  ...                     0   \n",
       "3      585.0                 0                  1  ...                     0   \n",
       "4        0.0                 1                  0  ...                     0   \n",
       "...      ...               ...                ...  ...                   ...   \n",
       "4272     0.0                 1                  0  ...                     0   \n",
       "4273   144.0                 1                  0  ...                     0   \n",
       "4274     0.0                 0                  0  ...                     0   \n",
       "4275   523.0                 0                  1  ...                     0   \n",
       "4276     0.0                 1                  0  ...                     0   \n",
       "\n",
       "      PassengerGroup_col_6  PassengerGroup_col_7  PassengerGroup_col_8  \\\n",
       "0                        0                     0                     1   \n",
       "1                        0                     0                     1   \n",
       "2                        0                     0                     0   \n",
       "3                        1                     0                     0   \n",
       "4                        1                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "4272                     0                     1                     0   \n",
       "4273                     0                     0                     1   \n",
       "4274                     0                     0                     0   \n",
       "4275                     1                     0                     0   \n",
       "4276                     0                     0                     0   \n",
       "\n",
       "      PassengerGroup_col_9  LastName_col_0  LastName_col_1  LastName_col_2  \\\n",
       "0                        0               0               1               0   \n",
       "1                        0               1               0               0   \n",
       "2                        0               0               0               0   \n",
       "3                        0               1               0               0   \n",
       "4                        0               1               0               0   \n",
       "...                    ...             ...             ...             ...   \n",
       "4272                     0               0               0               0   \n",
       "4273                     0               1               0               0   \n",
       "4274                     0               0               0               0   \n",
       "4275                     0               1               0               0   \n",
       "4276                     0               0               0               1   \n",
       "\n",
       "      LastName_col_3  LastName_col_4  \n",
       "0                  0               0  \n",
       "1                  0               0  \n",
       "2                  0               1  \n",
       "3                  0               0  \n",
       "4                  0               0  \n",
       "...              ...             ...  \n",
       "4272               1               0  \n",
       "4273               0               0  \n",
       "4274               0               1  \n",
       "4275               0               0  \n",
       "4276               0               0  \n",
       "\n",
       "[4277 rows x 39 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11466c50",
   "metadata": {},
   "source": [
    "### Variable Selection using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "24c61283",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1597634129.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [258]\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = lgb.LGBMClassifier(objective='binary', metric='accuracy', feature_fraction=0.8, lambda_l1=0.1, lambda_l2=0.1, dtrain, num_boost_round=100, verbose_eval=False)\u001b[0m\n\u001b[1;37m                                                                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def select_features_with_cv(X, y, n_splits=5):\n",
    "    \"\"\"\n",
    "    Performs feature selection on a pandas DataFrame using chi-squared test with cross-validation.\n",
    "\n",
    "    Args:\n",
    "        X (pandas.DataFrame): DataFrame containing the features.\n",
    "        y (pandas.Series): Series containing the target variable.\n",
    "        n_splits (int): Number of folds to use for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: New DataFrame containing the selected features and target variable.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set up a grid search to select the optimal number of features\n",
    "    param_grid = {'num_features': range(1, len(X.columns))}\n",
    "    best_num_features = None\n",
    "    best_score = 0\n",
    "\n",
    "    for num_features in param_grid['num_features']:\n",
    "        # Select the top 'num_features' features using chi-squared test\n",
    "        select_feature = SelectKBest(chi2, k=num_features).fit(X, y)\n",
    "        # Get the selected features\n",
    "        selected_features = X.columns[select_feature.get_support()]\n",
    "        # Use LightGBM with selected features\n",
    "        dtrain = lgb.Dataset(X[selected_features], label=y)\n",
    "        model = lgb.LGBMClassifier(objective='binary', metric='accuracy', feature_fraction=0.8, lambda_l1=0.1, lambda_l2=0.1, dtrain, num_boost_round=100, verbose_eval=False)\n",
    "        # Evaluate model performance with cross-validation\n",
    "        cv_scores = cross_val_score(model, X[selected_features], y, cv=KFold(n_splits=n_splits, shuffle=True, random_state=42))\n",
    "        mean_score = np.mean(cv_scores)\n",
    "        # Update best number of features and corresponding score\n",
    "        if mean_score > best_score:\n",
    "            best_num_features = num_features\n",
    "            best_score = mean_score\n",
    "\n",
    "    # Select the top 'best_num_features' features using chi-squared test\n",
    "    select_feature = SelectKBest(chi2, k=best_num_features).fit(X, y)\n",
    "    # Get the selected features\n",
    "    selected_features = X.columns[select_feature.get_support()]\n",
    "\n",
    "    # Create a new DataFrame with the selected features and target variable\n",
    "    selected_df = pd.concat([X[selected_features], y], axis=1)\n",
    "\n",
    "    return selected_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8f37ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train_data, label=Y_train_data)\n",
    "params = {'objective': 'binary', 'metric': 'binary_logloss', 'feature_fraction': 0.8, 'lambda_l1': 0.1, 'lambda_l2': 0.1}\n",
    "model = lgb.LGBMClassifier(params, dtrain, num_boost_round=100, verbose_eval=False)\n",
    "model.fit(X_train_data,Y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d5aaaf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 795, in fit\n    super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 594, in fit\n    self._Booster = train(params, train_set,\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\", line 228, in train\n    booster = Booster(params=params, train_set=train_set)\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1694, in __init__\n    params_str = param_dict_to_str(params)\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 140, in param_dict_to_str\n    raise TypeError('Unknown type of parameter:%s, got:%s'\nTypeError: Unknown type of parameter:boosting_type, got:dict\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [265]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mselect_features_with_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [256]\u001b[0m, in \u001b[0;36mselect_features_with_cv\u001b[1;34m(X, y, n_splits)\u001b[0m\n\u001b[0;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Evaluate model performance with cross-validation\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m mean_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cv_scores)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Update best number of features and corresponding score\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 795, in fit\n    super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 594, in fit\n    self._Booster = train(params, train_set,\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\", line 228, in train\n    booster = Booster(params=params, train_set=train_set)\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1694, in __init__\n    params_str = param_dict_to_str(params)\n  File \"C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 140, in param_dict_to_str\n    raise TypeError('Unknown type of parameter:%s, got:%s'\nTypeError: Unknown type of parameter:boosting_type, got:dict\n"
     ]
    }
   ],
   "source": [
    "df=select_features_with_cv(X_train_data, Y_train_data, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b39507",
   "metadata": {},
   "source": [
    "# Neural Network experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdbaeadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\usuario\\anaconda3\\lib\\site-packages (2.11.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\usuario\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\usuario\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\usuario\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\usuario\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\usuario\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -tatsmodels (c:\\users\\usuario\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.30.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.41.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.21)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9337c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "This type of normalization is a bad idea\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_data)\n",
    "X_test_data = pd.DataFrame(scaler.transform(X_test_data))\n",
    "X_train_data = pd.DataFrame(scaler.transform(X_train_data))\n",
    "\n",
    "\"\"\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data, Y_train_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d137111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "182/182 [==============================] - 3s 7ms/step - loss: 2.7590 - accuracy: 0.7400 - val_loss: 0.9678 - val_accuracy: 0.7644\n",
      "Epoch 2/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.7483 - accuracy: 0.7740 - val_loss: 0.5670 - val_accuracy: 0.7727\n",
      "Epoch 3/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.5836 - accuracy: 0.7776 - val_loss: 0.6391 - val_accuracy: 0.7769\n",
      "Epoch 4/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.6471 - accuracy: 0.7780 - val_loss: 0.6928 - val_accuracy: 0.7808\n",
      "Epoch 5/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.6003 - accuracy: 0.7876 - val_loss: 0.5173 - val_accuracy: 0.7863\n",
      "Epoch 6/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.7904 - val_loss: 0.5183 - val_accuracy: 0.7707\n",
      "Epoch 7/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.8010 - val_loss: 0.4581 - val_accuracy: 0.7811\n",
      "Epoch 8/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.4332 - accuracy: 0.7998 - val_loss: 0.4608 - val_accuracy: 0.7780\n",
      "Epoch 9/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.4261 - accuracy: 0.8051 - val_loss: 0.4566 - val_accuracy: 0.7846\n",
      "Epoch 10/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.4227 - accuracy: 0.8060 - val_loss: 0.4610 - val_accuracy: 0.7822\n",
      "Epoch 11/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.4220 - accuracy: 0.8089 - val_loss: 0.4510 - val_accuracy: 0.7811\n",
      "Epoch 12/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8103 - val_loss: 0.4393 - val_accuracy: 0.7902\n",
      "Epoch 13/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8110 - val_loss: 0.4372 - val_accuracy: 0.7853\n",
      "Epoch 14/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.4159 - accuracy: 0.8087 - val_loss: 0.4438 - val_accuracy: 0.7849\n",
      "Epoch 15/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4106 - accuracy: 0.8128 - val_loss: 0.4344 - val_accuracy: 0.7891\n",
      "Epoch 16/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.4056 - accuracy: 0.8154 - val_loss: 0.4434 - val_accuracy: 0.7874\n",
      "Epoch 17/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.4020 - accuracy: 0.8170 - val_loss: 0.4413 - val_accuracy: 0.7849\n",
      "Epoch 18/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.4027 - accuracy: 0.8158 - val_loss: 0.4434 - val_accuracy: 0.7898\n",
      "Epoch 19/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.4002 - accuracy: 0.8166 - val_loss: 0.4454 - val_accuracy: 0.7801\n",
      "Epoch 20/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3974 - accuracy: 0.8206 - val_loss: 0.4497 - val_accuracy: 0.7825\n",
      "Epoch 21/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.4495 - val_accuracy: 0.7853\n",
      "Epoch 22/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3954 - accuracy: 0.8223 - val_loss: 0.4617 - val_accuracy: 0.7877\n",
      "Epoch 23/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3922 - accuracy: 0.8201 - val_loss: 0.4518 - val_accuracy: 0.7870\n",
      "Epoch 24/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3910 - accuracy: 0.8178 - val_loss: 0.4503 - val_accuracy: 0.7801\n",
      "Epoch 25/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3887 - accuracy: 0.8190 - val_loss: 0.4570 - val_accuracy: 0.7815\n",
      "Epoch 26/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3871 - accuracy: 0.8221 - val_loss: 0.4511 - val_accuracy: 0.7863\n",
      "Epoch 27/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3875 - accuracy: 0.8243 - val_loss: 0.4614 - val_accuracy: 0.7860\n",
      "Epoch 28/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3921 - accuracy: 0.8194 - val_loss: 0.4684 - val_accuracy: 0.7752\n",
      "Epoch 29/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3925 - accuracy: 0.8197 - val_loss: 0.4688 - val_accuracy: 0.7835\n",
      "Epoch 30/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3873 - accuracy: 0.8194 - val_loss: 0.4682 - val_accuracy: 0.7773\n",
      "Epoch 31/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3873 - accuracy: 0.8231 - val_loss: 0.4720 - val_accuracy: 0.7863\n",
      "Epoch 32/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3832 - accuracy: 0.8237 - val_loss: 0.4690 - val_accuracy: 0.7842\n",
      "Epoch 33/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3812 - accuracy: 0.8225 - val_loss: 0.4895 - val_accuracy: 0.7811\n",
      "Epoch 34/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3808 - accuracy: 0.8240 - val_loss: 0.4790 - val_accuracy: 0.7769\n",
      "Epoch 35/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3771 - accuracy: 0.8266 - val_loss: 0.4683 - val_accuracy: 0.7835\n",
      "Epoch 36/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3832 - accuracy: 0.8243 - val_loss: 0.4701 - val_accuracy: 0.7738\n",
      "Epoch 37/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3827 - accuracy: 0.8235 - val_loss: 0.5008 - val_accuracy: 0.7881\n",
      "Epoch 38/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.8249 - val_loss: 0.5003 - val_accuracy: 0.7804\n",
      "Epoch 39/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3785 - accuracy: 0.8278 - val_loss: 0.5011 - val_accuracy: 0.7738\n",
      "Epoch 40/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3775 - accuracy: 0.8238 - val_loss: 0.4815 - val_accuracy: 0.7787\n",
      "Epoch 41/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3724 - accuracy: 0.8288 - val_loss: 0.5081 - val_accuracy: 0.7881\n",
      "Epoch 42/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3712 - accuracy: 0.8309 - val_loss: 0.5002 - val_accuracy: 0.7923\n",
      "Epoch 43/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3734 - accuracy: 0.8281 - val_loss: 0.4904 - val_accuracy: 0.7811\n",
      "Epoch 44/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3714 - accuracy: 0.8310 - val_loss: 0.5188 - val_accuracy: 0.7849\n",
      "Epoch 45/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3743 - accuracy: 0.8274 - val_loss: 0.4996 - val_accuracy: 0.7808\n",
      "Epoch 46/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3676 - accuracy: 0.8309 - val_loss: 0.5039 - val_accuracy: 0.7808\n",
      "Epoch 47/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3677 - accuracy: 0.8302 - val_loss: 0.5368 - val_accuracy: 0.7856\n",
      "Epoch 48/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3681 - accuracy: 0.8307 - val_loss: 0.4992 - val_accuracy: 0.7766\n",
      "Epoch 49/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3676 - accuracy: 0.8300 - val_loss: 0.5170 - val_accuracy: 0.7766\n",
      "Epoch 50/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3657 - accuracy: 0.8300 - val_loss: 0.4996 - val_accuracy: 0.7797\n",
      "Epoch 51/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3675 - accuracy: 0.8310 - val_loss: 0.5117 - val_accuracy: 0.7776\n",
      "Epoch 52/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3641 - accuracy: 0.8345 - val_loss: 0.5380 - val_accuracy: 0.7818\n",
      "Epoch 53/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3641 - accuracy: 0.8317 - val_loss: 0.5406 - val_accuracy: 0.7804\n",
      "Epoch 54/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.8322 - val_loss: 0.5147 - val_accuracy: 0.7741\n",
      "Epoch 55/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3655 - accuracy: 0.8307 - val_loss: 0.5403 - val_accuracy: 0.7874\n",
      "Epoch 56/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3623 - accuracy: 0.8322 - val_loss: 0.5312 - val_accuracy: 0.7829\n",
      "Epoch 57/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3636 - accuracy: 0.8322 - val_loss: 0.5300 - val_accuracy: 0.7863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3614 - accuracy: 0.8336 - val_loss: 0.5520 - val_accuracy: 0.7839\n",
      "Epoch 59/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3618 - accuracy: 0.8350 - val_loss: 0.5375 - val_accuracy: 0.7856\n",
      "Epoch 60/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3562 - accuracy: 0.8357 - val_loss: 0.5249 - val_accuracy: 0.7818\n",
      "Epoch 61/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3587 - accuracy: 0.8357 - val_loss: 0.5711 - val_accuracy: 0.7818\n",
      "Epoch 62/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3585 - accuracy: 0.8352 - val_loss: 0.5411 - val_accuracy: 0.7804\n",
      "Epoch 63/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3565 - accuracy: 0.8357 - val_loss: 0.5389 - val_accuracy: 0.7745\n",
      "Epoch 64/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3539 - accuracy: 0.8372 - val_loss: 0.5670 - val_accuracy: 0.7818\n",
      "Epoch 65/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3596 - accuracy: 0.8346 - val_loss: 0.5431 - val_accuracy: 0.7797\n",
      "Epoch 66/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3570 - accuracy: 0.8355 - val_loss: 0.5555 - val_accuracy: 0.7808\n",
      "Epoch 67/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3562 - accuracy: 0.8364 - val_loss: 0.6054 - val_accuracy: 0.7916\n",
      "Epoch 68/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3599 - accuracy: 0.8302 - val_loss: 0.5834 - val_accuracy: 0.7818\n",
      "Epoch 69/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3552 - accuracy: 0.8369 - val_loss: 0.5593 - val_accuracy: 0.7825\n",
      "Epoch 70/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3557 - accuracy: 0.8374 - val_loss: 0.5635 - val_accuracy: 0.7818\n",
      "Epoch 71/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3571 - accuracy: 0.8338 - val_loss: 0.5529 - val_accuracy: 0.7734\n",
      "Epoch 72/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3557 - accuracy: 0.8319 - val_loss: 0.5820 - val_accuracy: 0.7769\n",
      "Epoch 73/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3554 - accuracy: 0.8345 - val_loss: 0.5902 - val_accuracy: 0.7804\n",
      "Epoch 74/200\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3557 - accuracy: 0.8307 - val_loss: 0.5813 - val_accuracy: 0.7710\n",
      "Epoch 75/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3523 - accuracy: 0.8391 - val_loss: 0.5634 - val_accuracy: 0.7790\n",
      "Epoch 76/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3490 - accuracy: 0.8360 - val_loss: 0.5837 - val_accuracy: 0.7755\n",
      "Epoch 77/200\n",
      "182/182 [==============================] - 1s 4ms/step - loss: 0.3488 - accuracy: 0.8367 - val_loss: 0.5776 - val_accuracy: 0.7822\n",
      "Epoch 78/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3470 - accuracy: 0.8398 - val_loss: 0.5733 - val_accuracy: 0.7776\n",
      "Epoch 79/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3527 - accuracy: 0.8367 - val_loss: 0.5922 - val_accuracy: 0.7783\n",
      "Epoch 80/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8429 - val_loss: 0.5810 - val_accuracy: 0.7696\n",
      "Epoch 81/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3470 - accuracy: 0.8408 - val_loss: 0.5805 - val_accuracy: 0.7804\n",
      "Epoch 82/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3482 - accuracy: 0.8391 - val_loss: 0.5783 - val_accuracy: 0.7808\n",
      "Epoch 83/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3485 - accuracy: 0.8401 - val_loss: 0.5787 - val_accuracy: 0.7769\n",
      "Epoch 84/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8396 - val_loss: 0.5911 - val_accuracy: 0.7773\n",
      "Epoch 85/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8458 - val_loss: 0.6052 - val_accuracy: 0.7846\n",
      "Epoch 86/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3419 - accuracy: 0.8408 - val_loss: 0.6046 - val_accuracy: 0.7720\n",
      "Epoch 87/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3451 - accuracy: 0.8407 - val_loss: 0.5961 - val_accuracy: 0.7727\n",
      "Epoch 88/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3411 - accuracy: 0.8439 - val_loss: 0.5864 - val_accuracy: 0.7808\n",
      "Epoch 89/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8401 - val_loss: 0.6294 - val_accuracy: 0.7773\n",
      "Epoch 90/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3433 - accuracy: 0.8400 - val_loss: 0.6184 - val_accuracy: 0.7780\n",
      "Epoch 91/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3375 - accuracy: 0.8422 - val_loss: 0.6191 - val_accuracy: 0.7745\n",
      "Epoch 92/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8436 - val_loss: 0.6000 - val_accuracy: 0.7780\n",
      "Epoch 93/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3384 - accuracy: 0.8438 - val_loss: 0.6253 - val_accuracy: 0.7776\n",
      "Epoch 94/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8444 - val_loss: 0.5901 - val_accuracy: 0.7700\n",
      "Epoch 95/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3439 - accuracy: 0.8415 - val_loss: 0.6074 - val_accuracy: 0.7783\n",
      "Epoch 96/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3343 - accuracy: 0.8456 - val_loss: 0.6251 - val_accuracy: 0.7720\n",
      "Epoch 97/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3325 - accuracy: 0.8467 - val_loss: 0.6404 - val_accuracy: 0.7689\n",
      "Epoch 98/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3380 - accuracy: 0.8431 - val_loss: 0.6314 - val_accuracy: 0.7818\n",
      "Epoch 99/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3357 - accuracy: 0.8460 - val_loss: 0.6550 - val_accuracy: 0.7818\n",
      "Epoch 100/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3434 - accuracy: 0.8458 - val_loss: 0.6441 - val_accuracy: 0.7780\n",
      "Epoch 101/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3357 - accuracy: 0.8425 - val_loss: 0.6295 - val_accuracy: 0.7804\n",
      "Epoch 102/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3355 - accuracy: 0.8482 - val_loss: 0.6380 - val_accuracy: 0.7776\n",
      "Epoch 103/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3305 - accuracy: 0.8472 - val_loss: 0.6840 - val_accuracy: 0.7713\n",
      "Epoch 104/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3364 - accuracy: 0.8480 - val_loss: 0.6665 - val_accuracy: 0.7724\n",
      "Epoch 105/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3295 - accuracy: 0.8489 - val_loss: 0.6732 - val_accuracy: 0.7762\n",
      "Epoch 106/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3306 - accuracy: 0.8467 - val_loss: 0.6724 - val_accuracy: 0.7759\n",
      "Epoch 107/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.8492 - val_loss: 0.7028 - val_accuracy: 0.7717\n",
      "Epoch 108/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3271 - accuracy: 0.8475 - val_loss: 0.6880 - val_accuracy: 0.7780\n",
      "Epoch 109/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3280 - accuracy: 0.8468 - val_loss: 0.7233 - val_accuracy: 0.7713\n",
      "Epoch 110/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3314 - accuracy: 0.8472 - val_loss: 0.6745 - val_accuracy: 0.7707\n",
      "Epoch 111/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.8503 - val_loss: 0.7184 - val_accuracy: 0.7829\n",
      "Epoch 112/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3222 - accuracy: 0.8532 - val_loss: 0.7237 - val_accuracy: 0.7822\n",
      "Epoch 113/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3236 - accuracy: 0.8506 - val_loss: 0.6928 - val_accuracy: 0.7738\n",
      "Epoch 114/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3216 - accuracy: 0.8501 - val_loss: 0.6965 - val_accuracy: 0.7776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3236 - accuracy: 0.8530 - val_loss: 0.7183 - val_accuracy: 0.7738\n",
      "Epoch 116/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3190 - accuracy: 0.8501 - val_loss: 0.7087 - val_accuracy: 0.7762\n",
      "Epoch 117/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3222 - accuracy: 0.8525 - val_loss: 0.7472 - val_accuracy: 0.7766\n",
      "Epoch 118/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3202 - accuracy: 0.8516 - val_loss: 0.6963 - val_accuracy: 0.7741\n",
      "Epoch 119/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3250 - accuracy: 0.8499 - val_loss: 0.7183 - val_accuracy: 0.7755\n",
      "Epoch 120/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3185 - accuracy: 0.8546 - val_loss: 0.6982 - val_accuracy: 0.7797\n",
      "Epoch 121/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3206 - accuracy: 0.8563 - val_loss: 0.7364 - val_accuracy: 0.7734\n",
      "Epoch 122/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3210 - accuracy: 0.8506 - val_loss: 0.7239 - val_accuracy: 0.7696\n",
      "Epoch 123/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3177 - accuracy: 0.8556 - val_loss: 0.7226 - val_accuracy: 0.7724\n",
      "Epoch 124/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3158 - accuracy: 0.8535 - val_loss: 0.7617 - val_accuracy: 0.7703\n",
      "Epoch 125/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3205 - accuracy: 0.8520 - val_loss: 0.7621 - val_accuracy: 0.7748\n",
      "Epoch 126/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3165 - accuracy: 0.8522 - val_loss: 0.7790 - val_accuracy: 0.7727\n",
      "Epoch 127/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3185 - accuracy: 0.8553 - val_loss: 0.7696 - val_accuracy: 0.7679\n",
      "Epoch 128/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3127 - accuracy: 0.8571 - val_loss: 0.7749 - val_accuracy: 0.7713\n",
      "Epoch 129/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3154 - accuracy: 0.8570 - val_loss: 0.8095 - val_accuracy: 0.7752\n",
      "Epoch 130/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3155 - accuracy: 0.8530 - val_loss: 0.7479 - val_accuracy: 0.7713\n",
      "Epoch 131/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3151 - accuracy: 0.8534 - val_loss: 0.7680 - val_accuracy: 0.7717\n",
      "Epoch 132/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3132 - accuracy: 0.8523 - val_loss: 0.7971 - val_accuracy: 0.7759\n",
      "Epoch 133/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3144 - accuracy: 0.8534 - val_loss: 0.7644 - val_accuracy: 0.7794\n",
      "Epoch 134/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3141 - accuracy: 0.8551 - val_loss: 0.7493 - val_accuracy: 0.7707\n",
      "Epoch 135/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3120 - accuracy: 0.8542 - val_loss: 0.8358 - val_accuracy: 0.7741\n",
      "Epoch 136/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3143 - accuracy: 0.8532 - val_loss: 0.7931 - val_accuracy: 0.7748\n",
      "Epoch 137/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3137 - accuracy: 0.8565 - val_loss: 0.7936 - val_accuracy: 0.7731\n",
      "Epoch 138/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3071 - accuracy: 0.8595 - val_loss: 0.7969 - val_accuracy: 0.7731\n",
      "Epoch 139/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3139 - accuracy: 0.8566 - val_loss: 0.7608 - val_accuracy: 0.7720\n",
      "Epoch 140/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3104 - accuracy: 0.8590 - val_loss: 0.8216 - val_accuracy: 0.7776\n",
      "Epoch 141/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8566 - val_loss: 0.8354 - val_accuracy: 0.7755\n",
      "Epoch 142/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3152 - accuracy: 0.8549 - val_loss: 0.7767 - val_accuracy: 0.7724\n",
      "Epoch 143/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8577 - val_loss: 0.8173 - val_accuracy: 0.7713\n",
      "Epoch 144/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3111 - accuracy: 0.8585 - val_loss: 0.8214 - val_accuracy: 0.7693\n",
      "Epoch 145/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3067 - accuracy: 0.8594 - val_loss: 0.8036 - val_accuracy: 0.7741\n",
      "Epoch 146/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3079 - accuracy: 0.8582 - val_loss: 0.8979 - val_accuracy: 0.7745\n",
      "Epoch 147/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3065 - accuracy: 0.8604 - val_loss: 0.8642 - val_accuracy: 0.7734\n",
      "Epoch 148/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3092 - accuracy: 0.8575 - val_loss: 0.8215 - val_accuracy: 0.7693\n",
      "Epoch 149/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3105 - accuracy: 0.8563 - val_loss: 0.8119 - val_accuracy: 0.7647\n",
      "Epoch 150/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3076 - accuracy: 0.8590 - val_loss: 0.7900 - val_accuracy: 0.7686\n",
      "Epoch 151/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3039 - accuracy: 0.8618 - val_loss: 0.8184 - val_accuracy: 0.7720\n",
      "Epoch 152/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3015 - accuracy: 0.8587 - val_loss: 0.8260 - val_accuracy: 0.7717\n",
      "Epoch 153/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3056 - accuracy: 0.8602 - val_loss: 0.8675 - val_accuracy: 0.7769\n",
      "Epoch 154/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3041 - accuracy: 0.8614 - val_loss: 0.8490 - val_accuracy: 0.7720\n",
      "Epoch 155/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3079 - accuracy: 0.8561 - val_loss: 0.8581 - val_accuracy: 0.7727\n",
      "Epoch 156/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3073 - accuracy: 0.8606 - val_loss: 0.8445 - val_accuracy: 0.7741\n",
      "Epoch 157/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3021 - accuracy: 0.8613 - val_loss: 0.8984 - val_accuracy: 0.7745\n",
      "Epoch 158/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3010 - accuracy: 0.8640 - val_loss: 0.8541 - val_accuracy: 0.7741\n",
      "Epoch 159/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3059 - accuracy: 0.8599 - val_loss: 0.8380 - val_accuracy: 0.7755\n",
      "Epoch 160/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2978 - accuracy: 0.8625 - val_loss: 0.9058 - val_accuracy: 0.7717\n",
      "Epoch 161/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3008 - accuracy: 0.8623 - val_loss: 0.8694 - val_accuracy: 0.7766\n",
      "Epoch 162/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3032 - accuracy: 0.8589 - val_loss: 0.8923 - val_accuracy: 0.7752\n",
      "Epoch 163/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3022 - accuracy: 0.8613 - val_loss: 0.8897 - val_accuracy: 0.7776\n",
      "Epoch 164/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2967 - accuracy: 0.8657 - val_loss: 0.8743 - val_accuracy: 0.7752\n",
      "Epoch 165/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3115 - accuracy: 0.8628 - val_loss: 0.8910 - val_accuracy: 0.7776\n",
      "Epoch 166/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3015 - accuracy: 0.8606 - val_loss: 0.8865 - val_accuracy: 0.7741\n",
      "Epoch 167/200\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.3106 - accuracy: 0.8602 - val_loss: 0.8639 - val_accuracy: 0.7724\n",
      "Epoch 168/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3018 - accuracy: 0.8595 - val_loss: 0.9173 - val_accuracy: 0.7738\n",
      "Epoch 169/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3029 - accuracy: 0.8597 - val_loss: 0.8778 - val_accuracy: 0.7703\n",
      "Epoch 170/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2959 - accuracy: 0.8630 - val_loss: 0.9375 - val_accuracy: 0.7731\n",
      "Epoch 171/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.3070 - accuracy: 0.8602 - val_loss: 0.8643 - val_accuracy: 0.7700\n",
      "Epoch 172/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3002 - accuracy: 0.8599 - val_loss: 0.8614 - val_accuracy: 0.7720\n",
      "Epoch 173/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.2989 - accuracy: 0.8647 - val_loss: 0.8668 - val_accuracy: 0.7755\n",
      "Epoch 174/200\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.2940 - accuracy: 0.8597 - val_loss: 0.9458 - val_accuracy: 0.7738\n",
      "Epoch 175/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.2921 - accuracy: 0.8661 - val_loss: 1.0070 - val_accuracy: 0.7787\n",
      "Epoch 176/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2926 - accuracy: 0.8644 - val_loss: 0.9310 - val_accuracy: 0.7762\n",
      "Epoch 177/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2934 - accuracy: 0.8664 - val_loss: 0.8849 - val_accuracy: 0.7755\n",
      "Epoch 178/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.2934 - accuracy: 0.8659 - val_loss: 0.9324 - val_accuracy: 0.7776\n",
      "Epoch 179/200\n",
      "182/182 [==============================] - 2s 8ms/step - loss: 0.2966 - accuracy: 0.8649 - val_loss: 0.9109 - val_accuracy: 0.7665\n",
      "Epoch 180/200\n",
      "182/182 [==============================] - 2s 9ms/step - loss: 0.2952 - accuracy: 0.8630 - val_loss: 0.9829 - val_accuracy: 0.7665\n",
      "Epoch 181/200\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.2988 - accuracy: 0.8662 - val_loss: 0.8845 - val_accuracy: 0.7748\n",
      "Epoch 182/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.2915 - accuracy: 0.8638 - val_loss: 0.8817 - val_accuracy: 0.7745\n",
      "Epoch 183/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.2877 - accuracy: 0.8676 - val_loss: 0.9773 - val_accuracy: 0.7682\n",
      "Epoch 184/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.2960 - accuracy: 0.8625 - val_loss: 0.9080 - val_accuracy: 0.7741\n",
      "Epoch 185/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.3011 - accuracy: 0.8628 - val_loss: 0.9634 - val_accuracy: 0.7665\n",
      "Epoch 186/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.3120 - accuracy: 0.8575 - val_loss: 0.8745 - val_accuracy: 0.7741\n",
      "Epoch 187/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.2968 - accuracy: 0.8618 - val_loss: 0.8935 - val_accuracy: 0.7741\n",
      "Epoch 188/200\n",
      "182/182 [==============================] - 1s 8ms/step - loss: 0.2944 - accuracy: 0.8645 - val_loss: 0.8790 - val_accuracy: 0.7696\n",
      "Epoch 189/200\n",
      "182/182 [==============================] - 1s 7ms/step - loss: 0.2952 - accuracy: 0.8635 - val_loss: 0.9009 - val_accuracy: 0.7783\n",
      "Epoch 190/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2902 - accuracy: 0.8664 - val_loss: 0.9732 - val_accuracy: 0.7693\n",
      "Epoch 191/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2961 - accuracy: 0.8609 - val_loss: 0.8757 - val_accuracy: 0.7710\n",
      "Epoch 192/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2957 - accuracy: 0.8642 - val_loss: 0.9021 - val_accuracy: 0.7738\n",
      "Epoch 193/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2900 - accuracy: 0.8642 - val_loss: 0.9714 - val_accuracy: 0.7720\n",
      "Epoch 194/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2890 - accuracy: 0.8668 - val_loss: 0.9322 - val_accuracy: 0.7707\n",
      "Epoch 195/200\n",
      "182/182 [==============================] - 1s 6ms/step - loss: 0.2904 - accuracy: 0.8649 - val_loss: 0.9369 - val_accuracy: 0.7766\n",
      "Epoch 196/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2893 - accuracy: 0.8683 - val_loss: 0.9917 - val_accuracy: 0.7720\n",
      "Epoch 197/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2943 - accuracy: 0.8632 - val_loss: 0.9763 - val_accuracy: 0.7752\n",
      "Epoch 198/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2892 - accuracy: 0.8674 - val_loss: 0.9815 - val_accuracy: 0.7710\n",
      "Epoch 199/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2865 - accuracy: 0.8662 - val_loss: 1.0699 - val_accuracy: 0.7741\n",
      "Epoch 200/200\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.2869 - accuracy: 0.8657 - val_loss: 0.9445 - val_accuracy: 0.7745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9017931f0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(39,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d1ba350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "8688    0\n",
       "8689    0\n",
       "8690    1\n",
       "8691    0\n",
       "8692    1\n",
       "Length: 8693, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2daa9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = list(model.predict(X_test_data))\n",
    "prediction = [round(p[0]) for p in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "652f1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(\n",
    "{\n",
    "             'PassengerId': list(PassengerIdTest),\n",
    "             'Transported': [(p == 1) for p in list(prediction)]\n",
    "         }\n",
    ")\n",
    "res.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd9109e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec069c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>...</th>\n",
       "      <th>PassengerGroup_col_5</th>\n",
       "      <th>PassengerGroup_col_6</th>\n",
       "      <th>PassengerGroup_col_7</th>\n",
       "      <th>PassengerGroup_col_8</th>\n",
       "      <th>PassengerGroup_col_9</th>\n",
       "      <th>LastName_col_0</th>\n",
       "      <th>LastName_col_1</th>\n",
       "      <th>LastName_col_2</th>\n",
       "      <th>LastName_col_3</th>\n",
       "      <th>LastName_col_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall     Spa  \\\n",
       "0             0  39.0    0          0.0        0.0           0.0     0.0   \n",
       "1             0  24.0    0        109.0        9.0          25.0   549.0   \n",
       "2             0  58.0    1         43.0     3576.0           0.0  6715.0   \n",
       "3             0  33.0    0          0.0     1283.0         371.0  3329.0   \n",
       "4             0  16.0    0        303.0       70.0         151.0   565.0   \n",
       "...         ...   ...  ...          ...        ...           ...     ...   \n",
       "8688          0  41.0    1          0.0     6819.0           0.0  1643.0   \n",
       "8689          1  18.0    0          0.0        0.0           0.0     0.0   \n",
       "8690          0  26.0    0          0.0        0.0        1872.0     1.0   \n",
       "8691          0  32.0    0          0.0     1049.0           0.0   353.0   \n",
       "8692          0  44.0    0        126.0     4688.0           0.0     0.0   \n",
       "\n",
       "      VRDeck  HomePlanet_Earth  HomePlanet_Europa  ...  PassengerGroup_col_5  \\\n",
       "0        0.0                 0                  1  ...                     0   \n",
       "1       44.0                 1                  0  ...                     0   \n",
       "2       49.0                 0                  1  ...                     0   \n",
       "3      193.0                 0                  1  ...                     0   \n",
       "4        2.0                 1                  0  ...                     1   \n",
       "...      ...               ...                ...  ...                   ...   \n",
       "8688    74.0                 0                  1  ...                     0   \n",
       "8689     0.0                 1                  0  ...                     0   \n",
       "8690     0.0                 1                  0  ...                     0   \n",
       "8691  3235.0                 0                  1  ...                     0   \n",
       "8692    12.0                 0                  1  ...                     0   \n",
       "\n",
       "      PassengerGroup_col_6  PassengerGroup_col_7  PassengerGroup_col_8  \\\n",
       "0                        0                     0                     1   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "8688                     0                     0                     0   \n",
       "8689                     0                     1                     0   \n",
       "8690                     0                     0                     0   \n",
       "8691                     0                     0                     0   \n",
       "8692                     0                     0                     0   \n",
       "\n",
       "      PassengerGroup_col_9  LastName_col_0  LastName_col_1  LastName_col_2  \\\n",
       "0                        0               0               0               1   \n",
       "1                        0               0               0               0   \n",
       "2                        0               0               0               0   \n",
       "3                        0               0               0               0   \n",
       "4                        0               1               0               0   \n",
       "...                    ...             ...             ...             ...   \n",
       "8688                     0               0               1               0   \n",
       "8689                     0               0               0               0   \n",
       "8690                     1               0               0               0   \n",
       "8691                     0               0               0               1   \n",
       "8692                     0               0               0               1   \n",
       "\n",
       "      LastName_col_3  LastName_col_4  \n",
       "0                  0               0  \n",
       "1                  0               1  \n",
       "2                  0               1  \n",
       "3                  0               1  \n",
       "4                  0               0  \n",
       "...              ...             ...  \n",
       "8688               0               0  \n",
       "8689               0               1  \n",
       "8690               1               0  \n",
       "8691               0               0  \n",
       "8692               0               0  \n",
       "\n",
       "[8693 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5bd1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CryoSleep', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall',\n",
       "       'Spa', 'VRDeck', 'HomePlanet_Earth', 'HomePlanet_Europa',\n",
       "       'HomePlanet_Mars', 'Destination_55 Cancri e',\n",
       "       'Destination_PSO J318.5-22', 'Destination_TRAPPIST-1e', 'CabinDeck_A',\n",
       "       'CabinDeck_B', 'CabinDeck_C', 'CabinDeck_D', 'CabinDeck_E',\n",
       "       'CabinDeck_F', 'CabinDeck_G', 'CabinDeck_T', 'CabinSide_P',\n",
       "       'CabinSide_S', 'PassengerGroup_col_0', 'PassengerGroup_col_1',\n",
       "       'PassengerGroup_col_2', 'PassengerGroup_col_3', 'PassengerGroup_col_4',\n",
       "       'PassengerGroup_col_5', 'PassengerGroup_col_6', 'PassengerGroup_col_7',\n",
       "       'PassengerGroup_col_8', 'PassengerGroup_col_9', 'LastName_col_0',\n",
       "       'LastName_col_1', 'LastName_col_2', 'LastName_col_3', 'LastName_col_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a353a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy=pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07aa33c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Earth     4602\n",
       "Europa    2131\n",
       "Mars      1759\n",
       "Name: HomePlanet, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy.HomePlanet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aef21690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([433., 371., 989., 939., 569., 473., 268., 173.,  59.,  14.]),\n",
       " array([ 0. ,  7.8, 15.6, 23.4, 31.2, 39. , 46.8, 54.6, 62.4, 70.2, 78. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(copy[copy['Transported']==True].Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00552b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 158.,  278., 1100., 1037.,  719.,  435.,  283.,  143.,   54.,\n",
       "          19.]),\n",
       " array([ 0. ,  7.9, 15.8, 23.7, 31.6, 39.5, 47.4, 55.3, 63.2, 71.1, 79. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(copy[copy['Transported']==False].Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
